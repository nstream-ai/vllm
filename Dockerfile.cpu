# Base Image
FROM ubuntu:22.04 AS cpu-test-1

# Set Environment Variables
ENV CCACHE_DIR=/root/.cache/ccache
ENV CMAKE_CXX_COMPILER_LAUNCHER=ccache
ENV LD_PRELOAD="/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4:/usr/local/lib/libiomp5.so"
ENV PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu"

# Update and Install Dependencies
RUN apt-get update -y && \
    apt-get install -y \
        curl \
        ccache \
        git \
        wget \
        vim \
        numactl \
        gcc-12 \
        g++-12 \
        python3 \
        python3-pip \
        libtcmalloc-minimal4 \
        libnuma-dev \
        ffmpeg \
        libsm6 \
        libxext6 \
        libgl1 && \
    update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12

# Install Python Packages
RUN pip install --no-cache-dir intel-openmp

# Set ulimit in Bash Configuration
RUN echo 'ulimit -c 0' >> ~/.bashrc

# Install Intel Extension for PyTorch
RUN pip install --no-cache-dir intel_extension_for_pytorch==2.5.0

# Set Working Directory
WORKDIR /workspace

# Copy and Install Build Requirements
COPY requirements-build.txt /workspace/requirements-build.txt
RUN pip install --upgrade pip && \
    pip install --no-cache-dir -r requirements-build.txt

# Build Stage
FROM cpu-test-1 AS build

# Set Working Directory
WORKDIR /workspace/vllm

# Copy Common and CPU Requirements
COPY requirements-common.txt /workspace/requirements-common.txt
COPY requirements-cpu.txt /workspace/requirements-cpu.txt

# Install Common and CPU Requirements
RUN pip install --no-cache-dir -v -r requirements-cpu.txt

# Copy the Entire Repository
COPY . /workspace/vllm

# Conditional Git Repository Check
ARG GIT_REPO_CHECK=0
RUN if [ "$GIT_REPO_CHECK" != "0" ]; then bash tools/check_repo.sh; fi

# Handle AVX512 Configuration
ARG VLLM_CPU_DISABLE_AVX512
ENV VLLM_CPU_DISABLE_AVX512=${VLLM_CPU_DISABLE_AVX512}

# Build the Wheel and Install
RUN VLLM_TARGET_DEVICE=cpu python3 setup.py bdist_wheel && \
    pip install --no-cache-dir dist/*.whl && \
    rm -rf dist

# Set Working Directory Back
WORKDIR /workspace/

# Create Symbolic Links
RUN ln -s /workspace/vllm/tests /workspace/tests && \
    ln -s /workspace/vllm/examples /workspace/examples && \
    ln -s /workspace/vllm/benchmarks /workspace/benchmarks

# Install Development Dependencies for Testing
RUN pip install --no-cache-dir -e tests/vllm_test_utils

# Set Entry Point
ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
